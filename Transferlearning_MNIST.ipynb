{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM7oEWy2iZe8dMluMmBK5kd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmmanuelECCI/tensorflow_studies/blob/main/Transferlearning_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrDM5XKXM0bb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import PIL.Image as Image\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "D2iU56rvDclX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the images to floating-point numbers and rescale the pixel values to be between 0 and 1\n",
        "X_train = X_train.astype(\"float32\") / 255.0\n",
        "X_test = X_test.astype(\"float32\") / 255.0\n",
        "'''\n",
        "CHATGPT suggestion \n",
        "Converting the images to floating-point numbers also allows for more precision when working with the \n",
        "pixel values. Since the weights and biases of the neural network are also represented as floating-point \n",
        "numbers, having the input data in the same format can help with the overall performance and accuracy of \n",
        "the model.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "-eIKOqRWHAwY",
        "outputId": "b535bff5-939f-40b2-ce99-782fc874b1ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nCHATGPT suggestion \\nConverting the images to floating-point numbers also allows for more precision when working with the \\npixel values. Since the weights and biases of the neural network are also represented as floating-point \\nnumbers, having the input data in the same format can help with the overall performance and accuracy of \\nthe model.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Add a color channel dimension to the images\n",
        "X_train_resized = tf.repeat(X_train[..., tf.newaxis], 3, -1)\n",
        "X_test_resized = tf.repeat(X_test[..., tf.newaxis], 3, -1)\n"
      ],
      "metadata": {
        "id": "bpsbMkL1RCg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_resized.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GARFzIBpRT0k",
        "outputId": "bf838ce7-7e43-43de-d151-f3f275abcf95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([10000, 28, 28, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Modify the input layer to match the MNIST dataset\n",
        "inputs = tf.keras.Input(shape=(28, 28, 3))\n",
        "resized_inputs = tf.image.resize(inputs, (224, 224))\n",
        "x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(resized_inputs)\n",
        "#x = tf.keras.layers.experimental.preprocessing.Reshape((224, 224, 3))(x)\n",
        "\n",
        "# Load the pre-trained MobileNetV2 model without the top layer\n",
        "feature_extractor_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
        "pretrained_model_without_top_layer = hub.KerasLayer(feature_extractor_model, input_shape=(224, 224, 3), trainable=False)\n",
        "\n",
        "# Connect the new input layer to the pre-trained model\n",
        "x = pretrained_model_without_top_layer(x)\n",
        "\n",
        "# Create a new model that includes the pre-trained model and the new output layer\n",
        "outputs = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n"
      ],
      "metadata": {
        "id": "-muKNxmkDHV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.summary()\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "'''\n",
        "#We compile the model with the sparse_categorical_crossentropy loss function, which is appropriate for multiclass classification problems where the target values are integers\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "HjEo15FcL5-L",
        "outputId": "80733bb7-ac81-40f9-db48-dd26d5e10464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 28, 28, 3)]       0         \n",
            "                                                                 \n",
            " tf.image.resize_1 (TFOpLamb  (None, 224, 224, 3)      0         \n",
            " da)                                                             \n",
            "                                                                 \n",
            " rescaling_1 (Rescaling)     (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " keras_layer_1 (KerasLayer)  (None, 1280)              2257984   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                12810     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,270,794\n",
            "Trainable params: 12,810\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#We compile the model with the sparse_categorical_crossentropy loss function, which is appropriate for multiclass classification problems where the target values are integers\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs/\",histogram_freq=1)\n",
        "\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_resized, y_train, validation_data=(X_test_resized, y_test), epochs=10, batch_size=32,callbacks=[tb_callback])"
      ],
      "metadata": {
        "id": "xb-t86JiL8W1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f27f951-faa2-4c4d-a8f3-d71aed775410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 78s 39ms/step - loss: 1.9912 - accuracy: 0.3742 - val_loss: 1.6935 - val_accuracy: 0.6237\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 75s 40ms/step - loss: 1.5258 - accuracy: 0.6382 - val_loss: 1.3758 - val_accuracy: 0.6906\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 74s 39ms/step - loss: 1.2537 - accuracy: 0.7262 - val_loss: 1.1416 - val_accuracy: 0.7786\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 74s 40ms/step - loss: 1.0708 - accuracy: 0.7755 - val_loss: 0.9706 - val_accuracy: 0.8302\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 73s 39ms/step - loss: 0.9426 - accuracy: 0.8012 - val_loss: 0.8572 - val_accuracy: 0.8299\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 73s 39ms/step - loss: 0.8438 - accuracy: 0.8231 - val_loss: 0.7929 - val_accuracy: 0.8250\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 73s 39ms/step - loss: 0.7699 - accuracy: 0.8379 - val_loss: 0.7089 - val_accuracy: 0.8590\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 75s 40ms/step - loss: 0.7117 - accuracy: 0.8448 - val_loss: 0.6581 - val_accuracy: 0.8653\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 75s 40ms/step - loss: 0.6633 - accuracy: 0.8562 - val_loss: 0.6078 - val_accuracy: 0.8797\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 74s 40ms/step - loss: 0.6237 - accuracy: 0.8635 - val_loss: 0.5662 - val_accuracy: 0.8902\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5200bc2230>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Modify the input layer to match the MNIST dataset\n",
        "inputs = tf.keras.Input(shape=(28, 28, 3))\n",
        "resized_inputs = tf.image.resize(inputs, (224, 224))\n",
        "x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(resized_inputs)\n",
        "#x = tf.keras.layers.experimental.preprocessing.Reshape((224, 224, 3))(x)\n",
        "\n",
        "# Load the pre-trained MobileNetV2 model without the top layer\n",
        "feature_extractor_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
        "pretrained_model_without_top_layer = hub.KerasLayer(feature_extractor_model, input_shape=(224, 224, 3), trainable=False)\n",
        "\n",
        "# Connect the new input layer to the pre-trained model\n",
        "x = pretrained_model_without_top_layer(x)\n",
        "\n",
        "# Add a hidden layer with 64 units and ReLU activation\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
        "\n",
        "# Create a new output layer with 10 units and softmax activation for classification\n",
        "outputs = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "# Create the final model\n",
        "model_hidden = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model_hidden.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model_hidden.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6M0hgoRjKrO",
        "outputId": "3e0a0705-8579-4bec-b82f-301399c2990e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 28, 28, 3)]       0         \n",
            "                                                                 \n",
            " tf.image.resize_4 (TFOpLamb  (None, 224, 224, 3)      0         \n",
            " da)                                                             \n",
            "                                                                 \n",
            " rescaling_4 (Rescaling)     (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " keras_layer_4 (KerasLayer)  (None, 1280)              2257984   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                81984     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,340,618\n",
            "Trainable params: 82,634\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model_hidden.fit(X_train_resized, y_train, validation_data=(X_test_resized, y_test), epochs=10, batch_size=32,callbacks=[tb_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lKw-xdsjgIB",
        "outputId": "32e8f49d-417e-4ef9-e8b0-4c5f4f1a9657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 77s 39ms/step - loss: 2.0218 - accuracy: 0.2848 - val_loss: 1.6451 - val_accuracy: 0.3967\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 73s 39ms/step - loss: 1.4478 - accuracy: 0.5048 - val_loss: 1.2748 - val_accuracy: 0.5338\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 73s 39ms/step - loss: 1.1870 - accuracy: 0.6052 - val_loss: 1.0619 - val_accuracy: 0.6452\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 73s 39ms/step - loss: 1.0218 - accuracy: 0.6549 - val_loss: 0.9427 - val_accuracy: 0.6766\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 73s 39ms/step - loss: 0.9304 - accuracy: 0.6818 - val_loss: 0.9231 - val_accuracy: 0.6456\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 74s 39ms/step - loss: 0.8733 - accuracy: 0.6948 - val_loss: 0.8784 - val_accuracy: 0.7001\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 74s 39ms/step - loss: 0.8344 - accuracy: 0.7094 - val_loss: 0.7946 - val_accuracy: 0.7183\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 73s 39ms/step - loss: 0.8012 - accuracy: 0.7204 - val_loss: 0.7392 - val_accuracy: 0.7403\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 73s 39ms/step - loss: 0.7775 - accuracy: 0.7280 - val_loss: 0.7294 - val_accuracy: 0.7387\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 74s 39ms/step - loss: 0.7543 - accuracy: 0.7372 - val_loss: 0.7273 - val_accuracy: 0.7369\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5150126b30>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify the input layer to match the MNIST dataset\n",
        "inputs = tf.keras.Input(shape=(28, 28, 3))\n",
        "resized_inputs = tf.image.resize(inputs, (224, 224))\n",
        "x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(resized_inputs)\n",
        "#x = tf.keras.layers.experimental.preprocessing.Reshape((224, 224, 3))(x)\n",
        "\n",
        "# Load the pre-trained MobileNetV2 model without the top layer\n",
        "feature_extractor_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
        "pretrained_model_without_top_layer = hub.KerasLayer(feature_extractor_model, input_shape=(224, 224, 3), trainable=False)\n",
        "\n",
        "# Connect the new input layer to the pre-trained model\n",
        "x = pretrained_model_without_top_layer(x)\n",
        "\n",
        "# Add a hidden layer with 64 units and ReLU activation\n",
        "x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
        "\n",
        "# Create a new output layer with 10 units and softmax activation for classification\n",
        "outputs = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "# Create the final model\n",
        "model_hidden_2 = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model_hidden_2.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model_hidden_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPO9MzjXo0GC",
        "outputId": "16f06134-8ac0-49f4-f577-587cfe4a6b71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 28, 28, 3)]       0         \n",
            "                                                                 \n",
            " tf.image.resize_5 (TFOpLamb  (None, 224, 224, 3)      0         \n",
            " da)                                                             \n",
            "                                                                 \n",
            " rescaling_5 (Rescaling)     (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " keras_layer_5 (KerasLayer)  (None, 1280)              2257984   \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                81984     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,340,618\n",
            "Trainable params: 82,634\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model_hidden_2.fit(X_train_resized, y_train, validation_data=(X_test_resized, y_test), epochs=10, batch_size=32,callbacks=[tb_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDiUF1Cpo6Da",
        "outputId": "d9ca78a6-7bae-4de4-819b-e9e9ae216925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 78s 40ms/step - loss: 1.9404 - accuracy: 0.3334 - val_loss: 1.5103 - val_accuracy: 0.5523\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 73s 39ms/step - loss: 1.2573 - accuracy: 0.6154 - val_loss: 1.0398 - val_accuracy: 0.6531\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 73s 39ms/step - loss: 0.9370 - accuracy: 0.7103 - val_loss: 0.7987 - val_accuracy: 0.7615\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 73s 39ms/step - loss: 0.7815 - accuracy: 0.7582 - val_loss: 0.7609 - val_accuracy: 0.7592\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 73s 39ms/step - loss: 0.6799 - accuracy: 0.7903 - val_loss: 0.6228 - val_accuracy: 0.8006\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 74s 39ms/step - loss: 0.6059 - accuracy: 0.8151 - val_loss: 0.5472 - val_accuracy: 0.8307\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 74s 39ms/step - loss: 0.5525 - accuracy: 0.8300 - val_loss: 0.4778 - val_accuracy: 0.8647\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 74s 39ms/step - loss: 0.5056 - accuracy: 0.8457 - val_loss: 0.4507 - val_accuracy: 0.8704\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 74s 39ms/step - loss: 0.4671 - accuracy: 0.8573 - val_loss: 0.4161 - val_accuracy: 0.8758\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 74s 39ms/step - loss: 0.4436 - accuracy: 0.8629 - val_loss: 0.3804 - val_accuracy: 0.8888\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f520337f700>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}